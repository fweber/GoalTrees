{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If true, data is exported from the data acquisition database to csv files.\n",
    "# If false, data is read from csv files\n",
    "DB_Available=False\n",
    "\n",
    "if DB_Available:\n",
    "    from django.db.models import Model\n",
    "    from django.core.management.base import BaseCommand\n",
    "    from apps.construction import models\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import traceback\n",
    "import sys\n",
    "import django\n",
    "import scipy.stats\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import scikit_posthocs\n",
    "from autorank import autorank, plot_stats, create_report, latex_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# READ DATA\n",
    "If the script is run in the django environment with database and access via model class ORM, DB_Available is set to true.\n",
    "In this case, data is extracted from the database and saved to csv files.\n",
    "Otherwise, DB_Availabe is set to False, which leads to data being read from the previously exported csv\n",
    "files. The resulting dataframes are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Directory to which results and figures are saved\n",
    "EXPORT_PATH = \"{}/\".format(os.getcwd())\n",
    "\n",
    "\n",
    "\n",
    "if DB_Available:\n",
    "    # loads project settings from django and makes models accessible\n",
    "\n",
    "    from django_for_jupyter import init_django\n",
    "    init_django(\"goaltrees\")\n",
    "\n",
    "    # names of the studies to be included\n",
    "    studies=[\"pilot_study\",\"big5_study\"]\n",
    "\n",
    "    \n",
    "    # Get participant data and save as csv\n",
    "    \n",
    "    participants = models.Participant.objects.filter(study__name__in=studies,\n",
    "                                                     exclude_from_analyses=False,\n",
    "                                                     finished__isnull=False).order_by('id')\n",
    "\n",
    "    study_names=[]\n",
    "    for p in participants:\n",
    "        study_names.append(p.study.name)\n",
    "   \n",
    "    df_participants=pd.DataFrame(list(participants.values()))\n",
    "    df_participants=df_participants.set_index(\"id\")\n",
    "    df_participants[\"study_name\"]=study_names\n",
    "    df_participants.to_csv(\"{}/participants.csv\".format(EXPORT_PATH),\n",
    "                sep=\";\")\n",
    "\n",
    " \n",
    "            \n",
    "    # Get questions and save as csv\n",
    "\n",
    "    questions=models.Question.objects.filter(participant__in=participants).order_by(\"id\")\n",
    "    df_questions=pd.DataFrame(list(questions.values()))\n",
    "    df_questions=df_questions.set_index(\"id\")\n",
    "    \n",
    "    for q in questions:\n",
    "        # translate answering codes\n",
    "        translation=[0,4,3,2,1]\n",
    "        if (q.participant.study.name==\"pilot_study\") and (\"condition\" in q.question):\n",
    "            df_questions.at[q.pk, \"answer\"]= translation[int(q.answer)]\n",
    "    df_questions.to_csv(\"{}/questions.csv\".format(EXPORT_PATH),\n",
    "                sep=\";\")\n",
    "\n",
    "    \n",
    "    \n",
    "    ##########   export open questions   ##########\n",
    "    \n",
    "    questions = models.Question.objects.filter(participant__study__name__in=studies)\n",
    "\n",
    "    columns=[\"participant\",\"question\",\"answer\"]\n",
    "    \n",
    "    data={}\n",
    "    \n",
    "    for q in questions:\n",
    "        if \"condition\" not in q.question and q.answer:\n",
    "            data[q.pk]={\"participant\":q.participant.pk,\n",
    "                        \"question\":q.question,\n",
    "                        \"answer\":q.answer,}\n",
    "\n",
    "    df_open_questions=pd.DataFrame.from_dict(columns=columns,\n",
    "                              orient=\"index\",\n",
    "                              data=data,)\n",
    "\n",
    "    df_open_questions.to_csv(\"{}/open_questions.csv\".format(EXPORT_PATH),\n",
    "                   sep=\";\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "else: \n",
    "    df_participants=pd.read_csv(filepath_or_buffer=\"{}/participants.csv\".format(EXPORT_PATH), \n",
    "                                sep=\";\", \n",
    "                                index_col=\"id\",\n",
    "                               )\n",
    "    df_questions=pd.read_csv(filepath_or_buffer=\"{}/questions.csv\".format(EXPORT_PATH), \n",
    "                                sep=\";\",\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Participant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       participant_id         age    semester  degree\n",
      "count      120.000000  119.000000  118.000000     0.0\n",
      "mean       200.058333   23.529412    5.076271     NaN\n",
      "std        141.308608    6.422713    3.379569     NaN\n",
      "min         22.000000   16.000000    1.000000     NaN\n",
      "25%         87.250000   20.000000    2.000000     NaN\n",
      "50%        157.500000   22.000000    4.000000     NaN\n",
      "75%        301.750000   24.000000    6.000000     NaN\n",
      "max        542.000000   58.000000   20.000000     NaN\n",
      "total: 120\n",
      "male: 43\n",
      "female: 77\n",
      "Cognitive Science: 59\n",
      "Coxi Science: 1\n",
      "Psychologie: 30\n",
      "Psychologie : 2\n",
      "Biologie, Spanisch: 1\n",
      "Medieninformatik: 1\n",
      "cognitive science : 1\n",
      "Cogsci: 2\n",
      "psychologie: 1\n",
      "Cognitive science: 1\n",
      "International Business : 2\n",
      "Politikwissenschaft: 1\n",
      "B.Sc. Life Science: 1\n",
      "Maschinenbau Wirtschaft und Management: 1\n",
      "keines: 1\n",
      "Architektur: 1\n",
      "Rechtswissenschaft : 1\n",
      "Ev. Theologie/ Politik-Wirtschaft und DaF auf Gymnasiallehramt: 1\n",
      "PÃ¤dagogik der Kindheit: 1\n",
      "Lehramt: 1\n",
      "Anglistik und katholische Theologie: 1\n",
      "Cogntive Science: 1\n",
      "cognitive science: 1\n",
      "nan: 0\n",
      "Betriebswirtschaftslehre: 1\n",
      "Maschinenbau: 2\n",
      "Politik: 1\n",
      "Cognitive Science : 1\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "columns = [\"participant_id\", \"age\", \"gender\", \"semester\",\"subject\",\"degree\",\"screen_size\",\"operating_system\",\"browser_language\"]\n",
    "    \n",
    "    \n",
    "conditions=[\"ranking condition: {}\".format(x) for x in range(1,5)]\n",
    "\n",
    "for c in conditions:\n",
    "    columns.append(c)\n",
    "\n",
    "\n",
    "ids=df_participants.index\n",
    "\n",
    "for p_index, p_row in df_participants.iterrows():\n",
    "    data[p_index]={\"participant_id\":p_index,\n",
    "                    \"age\":p_row[\"age\"],\n",
    "                    \"gender\":p_row[\"gender\"],\n",
    "                    \"semester\":p_row[\"semester\"],\n",
    "                    \"subject\":p_row[\"subject\"],\n",
    "                    \"degree\":p_row[\"degree\"],\n",
    "                    \"screen_size\":p_row[\"screen_size\"],\n",
    "                    \"operating_system\":p_row[\"operating_system\"],\n",
    "                    \"browser_language\":p_row[\"browser_language\"],\n",
    "    }\n",
    "    for q_index, q_row in df_questions.iterrows():\n",
    "        if \"condition\" in q_row[\"question\"]:\n",
    "            for c in columns:\n",
    "                if c[-10:] == q_row[\"question\"][-10:]:\n",
    "                    data[p_index][c]=q_row[\"answer\"]\n",
    "\n",
    "\n",
    "                        \n",
    "                        \n",
    "df_study = pd.DataFrame.from_dict(data=data,\n",
    "                                     orient=\"index\",\n",
    "                                     columns=columns)\n",
    "\n",
    "print(df_study.describe())\n",
    "print(\"total: {}\".format(len(df_study)))\n",
    "print(\"male: {}\".format(len(df_study.loc[df_study['gender'] == \"male\"])))\n",
    "print(\"female: {}\".format(len(df_study.loc[df_study['gender'] == \"female\"])))\n",
    "\n",
    "for s in df_study[\"subject\"].unique():\n",
    "    print(\"{}: {}\".format(s, len(df_study.loc[df_study['subject'] == s])))\n",
    "\n",
    "df_study.to_csv(\"{}/merged_visu_data.csv\".format(EXPORT_PATH),\n",
    "                   sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visu Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "condition_1= [int(x) for x in df_study[\"ranking condition: 1\"]]\n",
    "condition_2 = [int(x) for x in df_study[\"ranking condition: 2\"]]\n",
    "condition_3 = [int(x) for x in df_study[\"ranking condition: 3\"]]\n",
    "condition_4 = [int(x) for x in df_study[\"ranking condition: 4\"]]\n",
    "\n",
    "samples = {\"condition 1\": condition_1,\n",
    "               \"condition 2\": condition_2,\n",
    "               \"condition 3\": condition_3,\n",
    "               \"condition 4\": condition_4,\n",
    "               }\n",
    "\n",
    "visualizations={\"condition 1\": \"sunburst\",\n",
    "               \"condition 2\": \"treemap\",\n",
    "               \"condition 3\": \"dendrogram\",\n",
    "               \"condition 4\": \"circlepacking\",\n",
    "               }\n",
    "\n",
    "columns=[\"participant\"]\n",
    "data={}\n",
    "for v in visualizations.values():\n",
    "    columns.append(v)\n",
    "for i in range(0, len(samples[\"condition 1\"])):\n",
    "    data[i]={\"participant\":i,\n",
    "                 visualizations[\"condition 1\"]:samples[\"condition 1\"][i],\n",
    "                 visualizations[\"condition 2\"]:samples[\"condition 2\"][i],\n",
    "                 visualizations[\"condition 3\"]:samples[\"condition 3\"][i],\n",
    "                 visualizations[\"condition 4\"]:samples[\"condition 4\"][i],}\n",
    "\n",
    "df_rankings = pd.DataFrame.from_dict(data=data,\n",
    "                                     orient=\"index\",\n",
    "                                     columns=columns)\n",
    "\n",
    "df_rankings.to_csv(\"{}/rankings.csv\".format(EXPORT_PATH),\n",
    "                   sep=\";\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columns=[\"visu 1\",\"visu 2\",\"first\",\"second\"]\n",
    "data={}\n",
    "for i in range(1,5):\n",
    "\n",
    "    for j in range(i + 1,5):\n",
    "\n",
    "        s1=\"condition {}\".format(i)\n",
    "        s2 =\"condition {}\".format(j)\n",
    "\n",
    "        data[\"{}{}\".format(s1,s2)]={\"visu 1\":visualizations[s1],\n",
    "                                        \"visu 2\":visualizations[s2],}\n",
    "\n",
    "    \n",
    "        # percentage\n",
    "\n",
    "        first=0\n",
    "        second=0\n",
    "        for x in range(0, len(samples[s1])):\n",
    "            if samples[s1][x] > samples[s2][x]:\n",
    "                second+=1\n",
    "            elif samples[s1][x] < samples[s2][x]:\n",
    "                first+=1\n",
    "\n",
    "        data[\"{}{}\".format(s1,s2)][\"first\"]=\"{:,.8f}\".format(first/len(samples[s1]))\n",
    "        data[\"{}{}\".format(s1,s2)][\"second\"]=\"{:,.8f}\".format(second/len(samples[s1]))\n",
    "\n",
    "        \n",
    "df_post_hoc = pd.DataFrame.from_dict(data=data,\n",
    "                                     orient=\"index\",\n",
    "                                     columns=columns)\n",
    "\n",
    "df_post_hoc.to_csv(\"{}/post_hoc.csv\".format(EXPORT_PATH),\n",
    "                   sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Friedman Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedmann statistic: 360.0000\n",
      "Friedmann p: 0.000000000000\n"
     ]
    }
   ],
   "source": [
    "##########   Friedman test   ##########\n",
    "\n",
    "result=scipy.stats.friedmanchisquare(condition_1,\n",
    "                        condition_2,\n",
    "                        condition_3,\n",
    "                        condition_4)\n",
    "\n",
    "print(\"Friedmann statistic: {:,.4f}\".format(result[0]))\n",
    "print(\"Friedmann p: {:,.12f}\".format(result[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nemenyi post-hoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nemenyi post-hoc Test for dendrogram and circlepacking\n",
      "Nemenyi post-hoc test\n",
      "       0      1      2      3\n",
      "0  1.000  0.001  0.001  0.001\n",
      "1  0.001  1.000  0.001  0.001\n",
      "2  0.001  0.001  1.000  0.001\n",
      "3  0.001  0.001  0.001  1.000\n",
      "RankResult(rankdf=\n",
      "               meanrank  mean  std ci_lower ci_upper effect_size magnitude\n",
      "treemap             4.0   1.0  0.0        1        1         NaN     large\n",
      "dendrogram          3.0   2.0  0.0        2        2        -inf     large\n",
      "sunburst            2.0   3.0  0.0        3        3        -inf     large\n",
      "circlepacking       1.0   4.0  0.0        4        4        -inf     large\n",
      "pvalue=1.0192622884900308e-77\n",
      "cd=0.428169268246638\n",
      "omnibus=friedman\n",
      "posthoc=nemenyi\n",
      "all_normal=True\n",
      "pvals_shapiro=[1.0, 1.0, 1.0, 1.0]\n",
      "homoscedastic=False\n",
      "pval_homogeneity=nan\n",
      "homogeneity_test=bartlett\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=120\n",
      "posterior_matrix=\n",
      "None\n",
      "decision_matrix=\n",
      "None\n",
      "rope=None\n",
      "rope_mode=None\n",
      "effect_size=cohen_d)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/scipy/stats/morestats.py:1678: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/scipy/stats/morestats.py:2267: RuntimeWarning: divide by zero encountered in log\n",
      "  numer = (Ntot*1.0 - k) * log(spsq) - np.sum((Ni - 1.0)*log(ssq), axis=0)\n",
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/scipy/stats/morestats.py:2267: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  numer = (Ntot*1.0 - k) * log(spsq) - np.sum((Ni - 1.0)*log(ssq), axis=0)\n",
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/autorank/_util.py:102: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (np.mean(x) - np.mean(y)) / _pooled_std(x, y)\n",
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/autorank/_util.py:102: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (np.mean(x) - np.mean(y)) / _pooled_std(x, y)\n",
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/scipy/stats/morestats.py:1678: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/autorank/_util.py:102: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return (np.mean(x) - np.mean(y)) / _pooled_std(x, y)\n",
      "/home/fweber/anaconda3/envs/django_py37/lib/python3.7/site-packages/autorank/_util.py:102: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return (np.mean(x) - np.mean(y)) / _pooled_std(x, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RankResult(rankdf=\n",
      "               mean  std ci_lower ci_upper effect_size magnitude  p_equal  \\\n",
      "circlepacking   4.0  0.0        4        4         NaN     large      NaN   \n",
      "sunburst        3.0  0.0        3        3         inf     large      0.0   \n",
      "dendrogram      2.0  0.0        2        2         inf     large      0.0   \n",
      "treemap         1.0  0.0        1        1         inf     large      0.0   \n",
      "\n",
      "               p_smaller decision  \n",
      "circlepacking        NaN       NA  \n",
      "sunburst             1.0  smaller  \n",
      "dendrogram           1.0  smaller  \n",
      "treemap              1.0  smaller  \n",
      "pvalue=None\n",
      "cd=None\n",
      "omnibus=bayes\n",
      "posthoc=bayes\n",
      "all_normal=True\n",
      "pvals_shapiro=[1.0, 1.0, 1.0, 1.0]\n",
      "homoscedastic=None\n",
      "pval_homogeneity=None\n",
      "homogeneity_test=None\n",
      "alpha=0.05\n",
      "alpha_normality=0.0125\n",
      "num_samples=120\n",
      "posterior_matrix=\n",
      "              circlepacking         sunburst       dendrogram          treemap\n",
      "circlepacking           NaN  (1.0, 0.0, 0.0)  (1.0, 0.0, 0.0)  (1.0, 0.0, 0.0)\n",
      "sunburst                NaN              NaN  (1.0, 0.0, 0.0)  (1.0, 0.0, 0.0)\n",
      "dendrogram              NaN              NaN              NaN  (1.0, 0.0, 0.0)\n",
      "treemap                 NaN              NaN              NaN              NaN\n",
      "decision_matrix=\n",
      "              circlepacking sunburst dendrogram  treemap\n",
      "circlepacking           NaN  smaller    smaller  smaller\n",
      "sunburst             larger      NaN    smaller  smaller\n",
      "dendrogram           larger   larger        NaN  smaller\n",
      "treemap              larger   larger     larger      NaN\n",
      "rope=0.1\n",
      "rope_mode=effsize\n",
      "effect_size=cohen_d)\n",
      "The statistical analysis was conducted for 4 populations with 120 paired samples.\n",
      "The family-wise significance level of the tests is alpha=0.050.\n",
      "We failed to reject the null hypothesis that the population is normal for all populations (minimal observed p-value=1.000). Therefore, we assume that all populations are normal.\n",
      "We used a bayesian signed rank test to determine differences between the mean values of the populations and report the mean value (M) and the standard deviation (SD) for each population. We distinguish between populations being pair-wise smaller, equal, or larger and make a decision for one of these cases if we estimate that the posterior probability is at least alpha=0.050.\n",
      "We used the effect size to define the region of practical equivalence (ROPE) around the mean value dynamically as 0.100*d.\n",
      "We found significant and practically relevant differences between the populations circlepacking (M=4.000+-0.000, SD=0.000), sunburst (M=3.000+-0.000, SD=0.000), dendrogram (M=2.000+-0.000, SD=0.000), and treemap (M=1.000+-0.000, SD=0.000).\n",
      "The mean value of the population circlepacking is larger than of the populations sunburst, dendrogram, and treemap.\n",
      "The mean value of the population sunburst is larger than of the populations dendrogram and treemap.\n",
      "The mean value of the population dendrogram is larger than of the populations treemap.\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\begin{tabular}{lrrlllrrl}\n",
      "\\toprule\n",
      "{} &     M &    SD &              CI & \\$d\\$ & Magnitude &  $P(\\textit{equal})$ &  $P(\\textit{smaller})$ & Decision \\\\\n",
      "\\midrule\n",
      "circlepacking & 4.000 & 0.000 &  [4.000, 4.000] &   - &     large &        - &          - &        - \\\\\n",
      "sunburst      & 3.000 & 0.000 &  [3.000, 3.000] & inf &     large &    0.000 &      1.000 &  smaller \\\\\n",
      "dendrogram    & 2.000 & 0.000 &  [2.000, 2.000] & inf &     large &    0.000 &      1.000 &  smaller \\\\\n",
      "treemap       & 1.000 & 0.000 &  [1.000, 1.000] & inf &     large &    0.000 &      1.000 &  smaller \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Summary of populations}\n",
      "\\label{tbl:stat_results}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "##########   Nemenyi post-hoc test  ##########\n",
    "\n",
    "print(\"Nemenyi post-hoc Test for {} and {}\".format(visualizations[s1], visualizations[s2]))\n",
    "\n",
    "\n",
    "data = np.array([samples[\"condition 1\"],\n",
    "                     samples[\"condition 2\"],\n",
    "                     samples[\"condition 3\"],\n",
    "                     samples[\"condition 4\"],\n",
    "                    ])\n",
    "\n",
    "result = scikit_posthocs.posthoc_nemenyi_friedman(data.T)\n",
    "\n",
    "print(\"Nemenyi post-hoc test\")\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########   descriptive statistics   ##########\n",
    "\n",
    "\n",
    "\n",
    "columns=[\"visualization\",\"R 1\", \"R 2\", \"R 3\", \"R 4\", \"rank sum\",\"average\", \"SD\"]\n",
    "data={}\n",
    "\n",
    "for s in samples.keys():\n",
    "    R1= 0\n",
    "    R2 = 0\n",
    "    R3 = 0\n",
    "    R4 = 0\n",
    "    sum = 0\n",
    "    for value in samples[s]:\n",
    "        sum+=value\n",
    "        if value==1:\n",
    "            R1+=1\n",
    "        elif value==2:\n",
    "            R2+=1\n",
    "        elif value==3:\n",
    "            R3+=1\n",
    "        elif value==4:\n",
    "            R4+=1\n",
    "        else:\n",
    "            print(\"ERROR: value is {}\".format(value))\n",
    "\n",
    "    data[visualizations[s]] = {}\n",
    "    data[visualizations[s]][\"visualization\"] = visualizations[s]\n",
    "    data[visualizations[s]][\"R 1\"] = \"{0:.0%}\".format(R1/len(samples[s]))\n",
    "    data[visualizations[s]][\"R 2\"] = \"{0:.0%}\".format(R2/len(samples[s]))\n",
    "    data[visualizations[s]][\"R 3\"] = \"{0:.0%}\".format(R3/len(samples[s]))\n",
    "    data[visualizations[s]][\"R 4\"] = \"{0:.0%}\".format(R4/len(samples[s]))\n",
    "    data[visualizations[s]][\"average\"] = \"{:,.2f}\".format(statistics.mean(samples[s]))\n",
    "    data[visualizations[s]][\"rank sum\"] = sum\n",
    "    data[visualizations[s]][\"SD\"] = \"{:,.2f}\".format(statistics.stdev(samples[s]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_sample = pd.DataFrame.from_dict(data=data,\n",
    "                                     orient=\"index\",\n",
    "                                     columns=columns)\n",
    "\n",
    "df_sample.to_csv(\"{}/merged_visu_data_statistics.csv\".format(EXPORT_PATH),\n",
    "                   sep=\";\")\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for c in samples.keys():\n",
    "    data[visualizations[c]]=[np.float64(x) for x in samples[c]]\n",
    "\n",
    "result = autorank(data, alpha=0.05, verbose=False)\n",
    "print(result)\n",
    "\n",
    "result = autorank(data, alpha=0.05, verbose=False, approach='bayesian')\n",
    "print(result)\n",
    "\n",
    "create_report(result)\n",
    "\n",
    "latex_table(result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}